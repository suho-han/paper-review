{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3fbbba1",
   "metadata": {},
   "source": [
    "## LLM Server Setup\n",
    "\n",
    "Use the unified Python launcher to start local vLLM servers before running these tests:\n",
    "\n",
    "- Start both 1B (8001) and 8B (8000):\n",
    "\n",
    "```bash\n",
    "python scripts/start_vllm.py start-both\n",
    "```\n",
    "\n",
    "- Start only 1B:\n",
    "\n",
    "```bash\n",
    "python scripts/start_vllm.py start-1b\n",
    "```\n",
    "\n",
    "- Start only 8B:\n",
    "\n",
    "```bash\n",
    "python scripts/start_vllm.py start-8b\n",
    "```\n",
    "\n",
    "This replaces the previous `scripts/start_llama_1b.sh`/`start_both_llm.sh` scripts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8974362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suhohan/paper-review/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import autorootcwd\n",
    "\n",
    "from src.agents.state import AgentState\n",
    "from src.agents.graph import build_agent_graph\n",
    "from src.agents.coordinator import CoordinatorAgent\n",
    "from src.agents.rating import RatingAgent\n",
    "from src.agents.reviewer import ReviewerAgent\n",
    "from src.agents.arxiv import ArxivPaperRetriever\n",
    "from src.agents.retriever import ReviewRetriever\n",
    "from src.agents.parser import ParserAgent\n",
    "from src.agents.llm import get_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f7514a",
   "metadata": {},
   "source": [
    "## 1. Environment & LLM Setup\n",
    "Check if the LLM is configured correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bd0c43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[get_llm] Using vLLM with model meta-llama/Meta-Llama-3-8B-Instruct at http://localhost:8000/v1\n",
      "LLM Initialized: client=<openai.resources.chat.completions.completions.Completions object at 0x7da39af7b8c0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7da1dcfb4440> root_client=<openai.OpenAI object at 0x7da39af79010> root_async_client=<openai.AsyncOpenAI object at 0x7da1dcfb41a0> model_name='meta-llama/Meta-Llama-3-8B-Instruct' temperature=0.3 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='http://localhost:8000/v1'\n"
     ]
    }
   ],
   "source": [
    "llm = get_llm()\n",
    "if llm:\n",
    "    print(f\"LLM Initialized: {llm}\")\n",
    "else:\n",
    "    print(\"LLM not configured. Some agents may not work fully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c37a3d",
   "metadata": {},
   "source": [
    "## 2. Parser Agent Test\n",
    "Test parsing raw text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b506a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParserAgent: Using local LLM for PDF cleanup.\n",
      "[get_llm] Using vLLM with model meta-llama/Llama-3.2-1B at http://localhost:8001/v1\n",
      "Parsed Sections: dict_keys(['abstract', 'conclusion', 'full_text', 'markdown_path'])\n",
      "Abstract: Existing video generation models struggle to maintain long-\n",
      "term spatial and temporal consistency due to the dense,\n",
      "high-dimensional nature of video signals.\n",
      "To overcome\n",
      "this limitation, we propose Spatia, a spatial memory–aware\n",
      "video generation framework that explicitly preserves a 3D\n",
      "scene point cloud as persistent spatial memory. Spatia it-\n",
      "eratively generates video clips conditioned on this spatial\n",
      "memory and continuously updates it through visual SLAM.\n",
      "This dynamic–static disentanglement de\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import src.agents.parser as parser_mod\n",
    "importlib.reload(parser_mod)\n",
    "ParserAgent = parser_mod.ParserAgent\n",
    "\n",
    "parser = ParserAgent()\n",
    "\n",
    "pdf_path = \"samples/2512.15716.pdf\"\n",
    "\n",
    "parsed = parser.parse(pdf_path=pdf_path, raw_text=None)\n",
    "print(\"Parsed Sections:\", parsed.keys())\n",
    "print(\"Abstract:\", parsed.get(\"abstract\", \"Not found\")[:500])\n",
    "if \"tables_md\" in parsed:\n",
    "    print(\"Tables captured (first 500 chars):\")\n",
    "    print(parsed[\"tables_md\"][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9cd978",
   "metadata": {},
   "source": [
    "## 3. Retriever Agent Test (ChromaDB)\n",
    "Test retrieving similar reviews from ChromaDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "441ebcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReviewRetriever initialized with 12 collections: ['neurips_2025', 'neurips_2022', 'iclr_2022', 'neurips_2024', 'iclr_2023', 'iclr_2021', 'neurips_2023', 'iclr_2025', 'iclr_2024', 'icml_2025', 'tmlr', 'neurips_2021']\n",
      "Retrieved 2 reviews.\n",
      "First review preview: Review: summary: This work proposes using video generation models (e.g., Hunyuan Video) to achieve s\n",
      "Metadata: {'note_id': '7vr2mRnyHF', 'forum_id': 'L1m5124sNQ', 'type': 'review', 'collection_name': 'neurips_2025', 'distance': 0.6797904372215271}\n"
     ]
    }
   ],
   "source": [
    "# Ensure you have the chromadb directory in the root or adjust path\n",
    "db_path = \"chromadb\"\n",
    "\n",
    "try:\n",
    "    retriever = ReviewRetriever(db_path=db_path)\n",
    "    query = \"Video Generation with Updatable Spatial Memory\"\n",
    "    results = retriever.retrieve_similar_reviews(query, k=2)\n",
    "\n",
    "    documents, metadatas, abstracts, paper_urls, pdf_urls, pdf_paths = results\n",
    "\n",
    "    print(f\"Retrieved {len(documents)} reviews.\")\n",
    "    if len(documents) > 0:\n",
    "        print(\"First review preview:\", documents[0][:100])\n",
    "        print(\"Metadata:\", metadatas[0])\n",
    "except Exception as e:\n",
    "    print(f\"Retriever test failed (check DB path): {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc423958",
   "metadata": {},
   "source": [
    "## 4. Arxiv Agent Test\n",
    "Test retrieving similar papers from Arxiv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41b4d5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache hit: True\n",
      "Found 3 papers.\n",
      "First paper title: Spatia: Video Generation with Updatable Spatial Memory\n"
     ]
    }
   ],
   "source": [
    "arxiv_agent = ArxivPaperRetriever(enable_cache=True, cache_path=\"../logs/arxiv_cache.json\")\n",
    "\n",
    "title = \"Spatia: Video Generation with Updatable Spatial Memory\"\n",
    "abstract = \"Existing video generation models struggle to maintain long-term spatial and temporal consistency due to the dense, high-dimensional nature of video signals. To overcome this limitation, we propose Spatia, a spatial memory–aware video generation framework that explicitly preserves a 3D scene point cloud as persistent spatial memory. Spatia iteratively generates video clips conditioned on this spatialmemory and continuously updates it through visual SLAM. This dynamic–static disentanglement design enhances spatial consistency throughout the generation process while preserving the model’s ability to produce realistic dynamic entities. Furthermore, Spatia enables applications such as explicit camera control and 3D-aware interactive editing, providing a geometrically grounded framework for scalable, memory-driven video generation\"\n",
    "papers, snippets, query, cache_hit = arxiv_agent.retrieve_similar_papers(\n",
    "    title=title,\n",
    "    abstract=abstract,\n",
    "    raw_text=\"\"\n",
    ")\n",
    "\n",
    "print(f\"Cache hit: {cache_hit}\")\n",
    "print(f\"Found {len(papers)} papers.\")\n",
    "if papers:\n",
    "    print(\"First paper title:\", papers[0].get(\"title\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45284203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-running the same query...\n",
      "Second run cache hit: True\n",
      "✅ Cache verification PASSED: Result served from cache.\n",
      "\n",
      "Reading cache file: ../logs/arxiv_cache.json\n",
      "Total cached queries: 3\n",
      "Sample cached query: 'attention is all you need'\n",
      "Cached data keys: ['papers', 'saved_at']\n"
     ]
    }
   ],
   "source": [
    "# 1. Run the same query again to verify cache hit\n",
    "import os\n",
    "import json\n",
    "print(\"Re-running the same query...\")\n",
    "_, _, _, cache_hit_2 = arxiv_agent.retrieve_similar_papers(\n",
    "    title=title,\n",
    "    abstract=abstract,\n",
    "    raw_text=\"\"\n",
    ")\n",
    "\n",
    "print(f\"Second run cache hit: {cache_hit_2}\")\n",
    "\n",
    "if cache_hit_2:\n",
    "    print(\"✅ Cache verification PASSED: Result served from cache.\")\n",
    "else:\n",
    "    print(\"❌ Cache verification FAILED: Result not served from cache.\")\n",
    "\n",
    "# 2. Check Cache File Structure\n",
    "\n",
    "cache_file_path = \"../logs/arxiv_cache.json\"\n",
    "\n",
    "if os.path.exists(cache_file_path):\n",
    "    print(f\"\\nReading cache file: {cache_file_path}\")\n",
    "    try:\n",
    "        with open(cache_file_path, 'r', encoding='utf-8') as f:\n",
    "            cache_data = json.load(f)\n",
    "\n",
    "        print(f\"Total cached queries: {len(cache_data)}\")\n",
    "\n",
    "        # Show a sample key (query)\n",
    "        if cache_data:\n",
    "            sample_query = list(cache_data.keys())[0]\n",
    "            print(f\"Sample cached query: '{sample_query}'\")\n",
    "            print(f\"Cached data keys: {list(cache_data[sample_query].keys())}\")  # Should be ['papers', 'timestamp']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading cache file: {e}\")\n",
    "else:\n",
    "    print(f\"Cache file not found at {cache_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa4976c",
   "metadata": {},
   "source": [
    "### ArXiv Caching Verification\n",
    "Check if the second request hits the cache and inspect the cache file structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264b334b",
   "metadata": {},
   "source": [
    "## 5. Reviewer Agent Test\n",
    "Test generating a review based on dummy inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1722f8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Review Preview:\n",
      "Here is the review:\n",
      "\n",
      "**Summary**\n",
      "\n",
      "The paper proposes a novel architecture for image classification, which is an interesting contribution to the field. However, the paper falls short in providing suffi...\n"
     ]
    }
   ],
   "source": [
    "reviewer = ReviewerAgent(llm=llm)\n",
    "\n",
    "paper_text = \"This paper proposes a novel architecture for image classification...\"\n",
    "similar_reviews = [\"This paper is good but lacks experiments.\", \"Novelty is limited.\"]\n",
    "arxiv_refs = [\"Related work A shows similar results.\"]\n",
    "\n",
    "review = reviewer.generate_review(\n",
    "    paper_text=paper_text,\n",
    "    similar_reviews=similar_reviews,\n",
    "    arxiv_references=arxiv_refs,\n",
    "    paper_title=\"Test Paper\"\n",
    ")\n",
    "\n",
    "print(\"Generated Review Preview:\")\n",
    "print(review[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc943b8",
   "metadata": {},
   "source": [
    "## 6. Rating Agent Test\n",
    "Test predicting a rating from a dummy review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2107a86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Score: 6.0\n",
      "Rationale: The paper's novel idea is a major strength, but poor writing and mediocre scores in other criteria bring down the overall score.\n"
     ]
    }
   ],
   "source": [
    "rating_agent = RatingAgent(llm=llm)\n",
    "\n",
    "dummy_review = \"\"\"\n",
    "Summary: Good paper.\n",
    "Strengths: Novel idea.\n",
    "Weaknesses: Poor writing.\n",
    "Rating: 7.5\n",
    "Detailed Review: ...\n",
    "\"\"\"\n",
    "\n",
    "score, rationale = rating_agent.predict_rating(dummy_review)\n",
    "print(f\"Predicted Score: {score}\")\n",
    "print(f\"Rationale: {rationale}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07695ba2",
   "metadata": {},
   "source": [
    "## 7. Coordinator Agent Test (Full Flow)\n",
    "Test the full flow using the coordinator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9268224c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReviewRetriever initialized with 12 collections: ['neurips_2025', 'neurips_2022', 'iclr_2022', 'neurips_2024', 'iclr_2023', 'iclr_2021', 'neurips_2023', 'iclr_2025', 'iclr_2024', 'icml_2025', 'tmlr', 'neurips_2021']\n",
      "[get_llm] Using vLLM with model meta-llama/Meta-Llama-3-8B-Instruct at http://localhost:8000/v1\n",
      "[get_llm] Using vLLM with model meta-llama/Meta-Llama-3-8B-Instruct at http://localhost:8000/v1\n",
      "ReviewRetriever initialized with 0 collections: []\n",
      "Final Rating: 1.0\n",
      "Progress Log:\n",
      " - Coordinator: Parser Agent starting...\n",
      " - Coordinator: Parser Agent completed.\n",
      " - Coordinator: RAG Agent starting retrieval...\n",
      " - Coordinator: RAG Agent retrieved references.\n",
      " - Coordinator: ArXiv Agent starting retrieval...\n",
      " - Coordinator: ArXiv Agent fetched related literature.\n",
      " - Coordinator: Reviewer Agent starting...\n",
      " - Coordinator: Reviewer Agent drafted report.\n",
      " - Coordinator: Rating Agent starting...\n",
      " - Coordinator: Rating Agent finalized the score.\n"
     ]
    }
   ],
   "source": [
    "coordinator = CoordinatorAgent()\n",
    "\n",
    "# We need to patch the retriever path if running from notebooks folder\n",
    "coordinator.retriever_agent = ReviewRetriever(db_path=\"../chromadb\")\n",
    "coordinator.arxiv_agent = ArxivPaperRetriever(cache_path=\"../logs/arxiv_cache.json\")\n",
    "\n",
    "state = coordinator.run(\n",
    "    paper_title=\"Test Paper for Coordination\",\n",
    "    paper_text=\"This is a test paper text for the coordinator agent to process.\"\n",
    ")\n",
    "\n",
    "print(\"Final Rating:\", state.get(\"predicted_rating\"))\n",
    "print(\"Progress Log:\")\n",
    "for log in state.get(\"progress_log\", []):\n",
    "    print(f\" - {log}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e3d4a7",
   "metadata": {},
   "source": [
    "## 8. LangGraph Workflow Test\n",
    "Test the graph execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48133165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Graph...\n",
      "Finished Node: parse\n",
      "--- RETRIEVE SIMILAR REVIEWS ---\n",
      "ReviewRetriever initialized with 12 collections: ['neurips_2025', 'neurips_2022', 'iclr_2022', 'neurips_2024', 'iclr_2023', 'iclr_2021', 'neurips_2023', 'iclr_2025', 'iclr_2024', 'icml_2025', 'tmlr', 'neurips_2021']\n",
      "Finished Node: retrieve\n",
      "Finished Node: arxiv\n",
      "--- GENERATE REVIEW ---\n",
      "[get_llm] Using vLLM with model meta-llama/Meta-Llama-3-8B-Instruct at http://localhost:8000/v1\n",
      "Finished Node: review\n",
      "[get_llm] Using vLLM with model meta-llama/Meta-Llama-3-8B-Instruct at http://localhost:8000/v1\n",
      "Finished Node: rate\n",
      "Graph execution finished.\n"
     ]
    }
   ],
   "source": [
    "# Note: The graph uses default initializations, so it might look for chromadb in ./chromadb relative to execution\n",
    "# You might need to adjust paths in the source code or run this from root if paths are hardcoded.\n",
    "\n",
    "try:\n",
    "    app = build_agent_graph()\n",
    "\n",
    "    inputs = AgentState(\n",
    "        paper_text=\"This paper proposes a new method for efficient transformer training...\",\n",
    "        paper_title=\"Efficient Training with LoRA\",\n",
    "        progress_log=[]\n",
    "    )\n",
    "\n",
    "    print(\"Starting Graph...\")\n",
    "    for output in app.stream(inputs):\n",
    "        for key, value in output.items():\n",
    "            print(f\"Finished Node: {key}\")\n",
    "\n",
    "    print(\"Graph execution finished.\")\n",
    "except Exception as e:\n",
    "    print(f\"Graph test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72688da9",
   "metadata": {},
   "source": [
    "## 9. Run Sample Paper Review\n",
    "Run the full multi-agent review process on the sample PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23ea192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autorootcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c41de083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ChromaDB at: chromadb\n",
      "Using ArXiv Cache at: logs/arxiv_cache.json\n",
      "Processing PDF: samples/sample_paper_deep_learning_STEM-EDX_tomography_of_nanocrystals.pdf\n",
      "\n",
      "--- Initializing LLMs ---\n",
      "[get_llm] Using vLLM with model meta-llama/Meta-Llama-3-8B-Instruct at http://localhost:8000/v1\n",
      "[get_llm] Using vLLM with model meta-llama/Llama-3.2-1B at http://localhost:8001/v1\n",
      "ReviewRetriever initialized with 12 collections: ['neurips_2025', 'neurips_2022', 'iclr_2022', 'neurips_2024', 'iclr_2023', 'iclr_2021', 'neurips_2023', 'iclr_2025', 'iclr_2024', 'icml_2025', 'tmlr', 'neurips_2021']\n",
      "ReviewRetriever initialized with 12 collections: ['neurips_2025', 'neurips_2022', 'iclr_2022', 'neurips_2024', 'iclr_2023', 'iclr_2021', 'neurips_2023', 'iclr_2025', 'iclr_2024', 'icml_2025', 'tmlr', 'neurips_2021']\n",
      "Error: Sample file not found at samples/sample_paper_deep_learning_STEM-EDX_tomography_of_nanocrystals.pdf\n"
     ]
    }
   ],
   "source": [
    "from src.agents import (ReviewerAgent, RatingAgent, ReviewRetriever, ArxivPaperRetriever)\n",
    "from src.agents.coordinator import CoordinatorAgent\n",
    "from src.agents.llm import get_llm\n",
    "\n",
    "import os\n",
    "import json\n",
    "import importlib\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import src.agents.llm\n",
    "import src.agents.coordinator\n",
    "\n",
    "importlib.reload(src.agents.llm)\n",
    "importlib.reload(src.agents.coordinator)\n",
    "\n",
    "\n",
    "def render_review_markdown(state, timestamp):\n",
    "    \"\"\"Render a human-readable markdown report covering every agent output.\"\"\"\n",
    "    def _trim_text(value, limit=1200):\n",
    "        if not value:\n",
    "            return \"\"\n",
    "        text = str(value)\n",
    "        return text if len(text) <= limit else f\"{text[:limit]}...[truncated]\"\n",
    "\n",
    "    parsed_sections = state.get(\"parsed_sections\") or {}\n",
    "    retrieved_reviews = state.get(\"retrieved_reviews\") or []\n",
    "    metadatas = state.get(\"retrieved_metadatas\") or []\n",
    "    abstracts = state.get(\"retrieved_abstracts\") or []\n",
    "    paper_urls = state.get(\"retrieved_paper_urls\") or []\n",
    "    pdf_urls = state.get(\"retrieved_pdf_urls\") or []\n",
    "    pdf_paths = state.get(\"retrieved_pdf_paths\") or []\n",
    "    arxiv_results = state.get(\"arxiv_results\") or []\n",
    "    arxiv_snippets = state.get(\"arxiv_reference_texts\") or []\n",
    "    lines = [\n",
    "        f\"# Review Generation Result - {timestamp}\",\n",
    "        \"\",\n",
    "        \"## Paper Information\",\n",
    "        f\"- **Paper Title:** {state.get('paper_title') or 'N/A'}\",\n",
    "        f\"- **PDF Path:** {state.get('paper_pdf_path') or 'N/A'}\",\n",
    "        f\"- **ArXiv Query:** {state.get('arxiv_query') or 'N/A'}\",\n",
    "        f\"- **ArXiv Cache Hit:** {state.get('arxiv_cache_hit')}\",\n",
    "        \"\",\n",
    "        \"## Parser Output\",\n",
    "    ]\n",
    "\n",
    "    if parsed_sections:\n",
    "        for section_name, section_text in parsed_sections.items():\n",
    "            lines.append(f\"### {section_name.title()}\")\n",
    "            lines.append(_trim_text(section_text, limit=2000) or \"_Empty section_\")\n",
    "            lines.append(\"\")\n",
    "    else:\n",
    "        lines.append(\"_No parser output available._\")\n",
    "        lines.append(\"\")\n",
    "\n",
    "    lines.append(\"## Retrieved Reviews\")\n",
    "    if retrieved_reviews:\n",
    "        for idx, review_text in enumerate(retrieved_reviews, start=1):\n",
    "            meta = metadatas[idx - 1] if idx - 1 < len(metadatas) else {}\n",
    "            abstract = abstracts[idx - 1] if idx - 1 < len(abstracts) else \"\"\n",
    "            paper_url = paper_urls[idx - 1] if idx - 1 < len(paper_urls) else \"\"\n",
    "            pdf_url = pdf_urls[idx - 1] if idx - 1 < len(pdf_urls) else \"\"\n",
    "            pdf_path = pdf_paths[idx - 1] if idx - 1 < len(pdf_paths) else \"\"\n",
    "            lines.append(f\"### Retrieved Review {idx}\")\n",
    "            lines.append(f\"- **Paper URL:** {paper_url or 'N/A'}\")\n",
    "            lines.append(f\"- **PDF URL:** {pdf_url or 'N/A'}\")\n",
    "            lines.append(f\"- **PDF Path:** {pdf_path or 'N/A'}\")\n",
    "            lines.append(f\"- **Metadata:** {json.dumps(meta, ensure_ascii=False)}\")\n",
    "            lines.append(\"\")\n",
    "            lines.append(\"**Related Abstract:**\")\n",
    "            lines.append(_trim_text(abstract, limit=1500) or \"_No abstract available._\")\n",
    "            lines.append(\"\")\n",
    "            lines.append(\"**Review Snippet:**\")\n",
    "            lines.append(_trim_text(review_text, limit=2000) or \"_No review available._\")\n",
    "            lines.append(\"\")\n",
    "    else:\n",
    "        lines.append(\"_No retrieved reviews available._\")\n",
    "        lines.append(\"\")\n",
    "\n",
    "    lines.append(\"## ArXiv Matches\")\n",
    "    if arxiv_results:\n",
    "        for idx, paper in enumerate(arxiv_results, start=1):\n",
    "            snippet = arxiv_snippets[idx - 1] if idx - 1 < len(arxiv_snippets) else \"\"\n",
    "            lines.append(f\"### Match {idx}\")\n",
    "            lines.append(f\"- **Title:** {paper.get('title', 'N/A')}\")\n",
    "            lines.append(f\"- **URL:** {paper.get('url', 'N/A')}\")\n",
    "            lines.append(f\"- **PDF URL:** {paper.get('pdf_url', 'N/A')}\")\n",
    "            lines.append(f\"- **Published:** {paper.get('published', 'N/A')}\")\n",
    "            lines.append(f\"- **Authors:** {', '.join(paper.get('authors', [])) or 'N/A'}\")\n",
    "            lines.append(\"\")\n",
    "            lines.append(\"**Summary:**\")\n",
    "            lines.append(_trim_text(paper.get(\"summary\", \"\"), limit=2000) or \"_No summary available._\")\n",
    "            lines.append(\"\")\n",
    "            if snippet:\n",
    "                lines.append(\"**Reference Snippet:**\")\n",
    "                lines.append(_trim_text(snippet, limit=1500))\n",
    "                lines.append(\"\")\n",
    "    else:\n",
    "        lines.append(\"_No related arXiv papers found._\")\n",
    "        lines.append(\"\")\n",
    "\n",
    "    lines.append(\"## Final Review\")\n",
    "    lines.append(state.get(\"final_review\") or \"_No final review produced._\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"## Rating Prediction\")\n",
    "    lines.append(f\"- **Score:** {state.get('predicted_rating')}\")\n",
    "    lines.append(f\"- **Rationale:** {state.get('rating_rationale') or 'N/A'}\")\n",
    "    lines.append(\"\")\n",
    "    lines.append(\"## Progress Log\")\n",
    "    progress_log = state.get(\"progress_log\", [])\n",
    "    if progress_log:\n",
    "        for log in progress_log:\n",
    "            lines.append(f\"- {log}\")\n",
    "    else:\n",
    "        lines.append(\"- No progress recorded.\")\n",
    "    lines.append(\"\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def save_agent_outputs(state, output_root=\"outputs\"):\n",
    "    \"\"\"Persist raw agent state (JSON) plus a markdown summary under outputs/.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    output_root = Path(output_root)\n",
    "    results_dir = output_root / \"results\"\n",
    "    results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    state_path = results_dir / f\"agent_state_{timestamp}.json\"\n",
    "    report_path = results_dir / f\"review_{timestamp}.md\"\n",
    "\n",
    "    with state_path.open(\"w\", encoding=\"utf-8\") as fp:\n",
    "        json.dump(state, fp, ensure_ascii=False, indent=2, default=str)\n",
    "\n",
    "    report_path.write_text(render_review_markdown(state, timestamp), encoding=\"utf-8\")\n",
    "    return state_path, report_path\n",
    "\n",
    "\n",
    "# Define paths relative to the notebook\n",
    "chroma_path = os.path.join(\"chromadb\")\n",
    "cache_path = os.path.join(\"logs\", \"arxiv_cache.json\")\n",
    "sample_pdf_path = os.path.join(\"samples\", \"sample_paper_deep_learning_STEM-EDX_tomography_of_nanocrystals.pdf\")\n",
    "\n",
    "print(f\"Using ChromaDB at: {chroma_path}\")\n",
    "print(f\"Using ArXiv Cache at: {cache_path}\")\n",
    "print(f\"Processing PDF: {sample_pdf_path}\")\n",
    "\n",
    "# 1. Initialize LLMs\n",
    "print(\"\\n--- Initializing LLMs ---\")\n",
    "\n",
    "# Main model (8B) on port 8000 (Replaces Gemini)\n",
    "llama_8b = get_llm(\n",
    "    provider=\"vllm\",\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    model=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# Small model (1B) on port 8001 (Replaces previous OSS LLM usage)\n",
    "# Ensure you have started the server using `scripts/start_llama_1b.sh`\n",
    "llama_1b = get_llm(\n",
    "    provider=\"vllm\",\n",
    "    base_url=\"http://localhost:8001/v1\",\n",
    "    model=\"meta-llama/Llama-3.2-1B\",\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# Alternative: Use HuggingFace Local Pipeline for 1B if server is not desired\n",
    "# llama_1b = get_llm(provider=\"huggingface\", model=\"meta-llama/Llama-3.2-1B\")\n",
    "\n",
    "if not llama_8b:\n",
    "    print(\"⚠️ Llama-8B not available. Check if vLLM server is running on port 8000.\")\n",
    "if not llama_1b:\n",
    "    print(\"⚠️ Llama-1B not available. Check if vLLM server is running on port 8001.\")\n",
    "\n",
    "# 2. Initialize Agents with specific LLMs\n",
    "# Reviewer & Rating -> Llama 8B (was Gemini)\n",
    "reviewer = ReviewerAgent(llm=llama_8b)\n",
    "rating = RatingAgent(llm=llama_8b)\n",
    "\n",
    "# Coordinator -> Llama 1B (was OSS LLM)\n",
    "# We inject the 8B-powered agents into the Coordinator, but Coordinator itself might use 1B for orchestration if needed\n",
    "coordinator = CoordinatorAgent(\n",
    "    reviewer_agent=reviewer,\n",
    "    rating_agent=rating,\n",
    "    llm=llama_8b  # Assuming Coordinator accepts an LLM for its own operations\n",
    ")\n",
    "\n",
    "# Patch paths for retriever/arxiv agents inside coordinator\n",
    "coordinator.retriever_agent = ReviewRetriever(db_path=chroma_path)\n",
    "coordinator.arxiv_agent = ArxivPaperRetriever(cache_path=cache_path)\n",
    "\n",
    "# Run the review process\n",
    "if os.path.exists(sample_pdf_path):\n",
    "    print(\"\\nStarting review generation... This may take a few minutes.\")\n",
    "    state = coordinator.run(\n",
    "        paper_pdf_path=sample_pdf_path,\n",
    "        paper_title=\"Deep Learning STEM-EDX Tomography of Nanocrystals\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"       FINAL REVIEW REPORT       \")\n",
    "    print(\"=\"*30 + \"\\n\")\n",
    "    print(state.get(\"final_review\"))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"       RATING PREDICTION       \")\n",
    "    print(\"=\"*30 + \"\\n\")\n",
    "    print(f\"Score: {state.get('predicted_rating')}\")\n",
    "    print(f\"Rationale: {state.get('rating_rationale')}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"       PROGRESS LOG       \")\n",
    "    print(\"=\"*30 + \"\\n\")\n",
    "    for log in state.get(\"progress_log\", []):\n",
    "        print(f\" - {log}\")\n",
    "\n",
    "    state_path, report_path = save_agent_outputs(state)\n",
    "    print(\"\\nSaved agent state to:\", state_path)\n",
    "    print(\"Saved markdown report to:\", report_path)\n",
    "else:\n",
    "    print(f\"Error: Sample file not found at {sample_pdf_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper-review",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
